{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1af9602",
   "metadata": {},
   "source": [
    "# Training Accuracy Visualization for Sentiment Analysis Model\n",
    "\n",
    "This notebook demonstrates multiple ways to visualize training accuracy from your sentiment analysis model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ca7cb",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import matplotlib, seaborn, numpy, and other necessary libraries for data visualization and handling training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c800d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plotly\n",
    "\n",
    "# Import Required Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import glob\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "# Set style for better looking plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05a37b",
   "metadata": {},
   "source": [
    "## 2. Load Training Data from TensorBoard Logs\n",
    "Load training history data from TensorBoard event files or create sample training accuracy data for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8461d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensorboard_data(log_dir):\n",
    "    \"\"\"Load training metrics from TensorBoard event files\"\"\"\n",
    "    \n",
    "    # Find all event files in the log directory\n",
    "    event_files = glob.glob(os.path.join(log_dir, \"events.out.tfevents.*\"))\n",
    "    \n",
    "    if not event_files:\n",
    "        print(f\"No TensorBoard event files found in {log_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Use the most recent event file\n",
    "    latest_file = max(event_files, key=os.path.getctime)\n",
    "    print(f\"Loading data from: {latest_file}\")\n",
    "    \n",
    "    # Load the event accumulator\n",
    "    ea = EventAccumulator(latest_file)\n",
    "    ea.Reload()\n",
    "    \n",
    "    # Get available scalar tags\n",
    "    available_tags = ea.Tags()['scalars']\n",
    "    print(f\"Available metrics: {available_tags}\")\n",
    "    \n",
    "    # Extract training metrics\n",
    "    metrics_data = {}\n",
    "    \n",
    "    for tag in available_tags:\n",
    "        scalar_events = ea.Scalars(tag)\n",
    "        steps = [event.step for event in scalar_events]\n",
    "        values = [event.value for event in scalar_events]\n",
    "        metrics_data[tag] = {'steps': steps, 'values': values}\n",
    "    \n",
    "    return metrics_data\n",
    "\n",
    "# Try to load actual training data\n",
    "log_dir = \"./logs\"\n",
    "training_data = load_tensorboard_data(log_dir)\n",
    "\n",
    "# If no TensorBoard data available, create sample data\n",
    "if training_data is None:\n",
    "    print(\"\\nCreating sample training data for demonstration...\")\n",
    "    \n",
    "    # Sample training data that mimics real training\n",
    "    epochs = np.arange(1, 4)  # 3 epochs as in your config\n",
    "    steps = np.arange(0, 3000, 100)  # Steps every 100 iterations\n",
    "    \n",
    "    # Simulate training accuracy that improves over time\n",
    "    train_acc = 0.65 + 0.25 * (1 - np.exp(-steps / 800)) + np.random.normal(0, 0.02, len(steps))\n",
    "    train_acc = np.clip(train_acc, 0.5, 0.95)\n",
    "    \n",
    "    # Simulate validation accuracy (slightly lower and more volatile)\n",
    "    val_acc = train_acc - 0.05 + np.random.normal(0, 0.03, len(steps))\n",
    "    val_acc = np.clip(val_acc, 0.45, 0.90)\n",
    "    \n",
    "    # Simulate loss (decreasing)\n",
    "    train_loss = 1.2 * np.exp(-steps / 1000) + 0.1 + np.random.normal(0, 0.05, len(steps))\n",
    "    train_loss = np.clip(train_loss, 0.1, 1.5)\n",
    "    \n",
    "    training_data = {\n",
    "        'train/accuracy': {'steps': steps.tolist(), 'values': train_acc.tolist()},\n",
    "        'eval/accuracy': {'steps': steps[::5].tolist(), 'values': val_acc[::5].tolist()},  # Eval less frequent\n",
    "        'train/loss': {'steps': steps.tolist(), 'values': train_loss.tolist()}\n",
    "    }\n",
    "    \n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"Available metrics: {list(training_data.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d32fe",
   "metadata": {},
   "source": [
    "## 3. Plot Training Accuracy Over Steps\n",
    "Create line plots showing how training accuracy changes over training steps using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b45000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use epochs instead of steps for x-axis\n",
    "# Construct df_export DataFrame from training_data, aligning by position\n",
    "min_len = min(\n",
    "    len(training_data['eval/accuracy']['values']),\n",
    "    len(training_data['eval/loss']['values']),\n",
    "    len(training_data['train/epoch']['values'])\n",
    ")\n",
    "\n",
    "df_export = pd.DataFrame({\n",
    "    'eval/accuracy': training_data['eval/accuracy']['values'][:min_len],\n",
    "    'eval/loss': training_data['eval/loss']['values'][:min_len],\n",
    "    'train/epoch': training_data['train/epoch']['values'][:min_len]\n",
    "})\n",
    "\n",
    "eval_df = df_export.dropna(subset=['eval/accuracy', 'eval/loss', 'train/epoch'])\n",
    "\n",
    "epochs = eval_df['train/epoch'].values\n",
    "eval_acc = eval_df['eval/accuracy'].values\n",
    "eval_loss = eval_df['eval/loss'].values\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8,5))\n",
    "fig.suptitle('Sentiment Evaluation Progress Visualization', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Eval Accuracy over Epochs\n",
    "axes[0, 0].plot(epochs, eval_acc, 'b-', linewidth=2, label='Eval Accuracy')\n",
    "axes[0, 0].set_title('Evaluation Accuracy Over Epochs')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].text(0.7, 0.1, f'Final Accuracy: {eval_acc[-1]:.3f}',\n",
    "                transform=axes[0, 0].transAxes,\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "# Plot 2: Eval Loss over Epochs\n",
    "axes[0, 1].plot(epochs, eval_loss, 'r-', linewidth=2, label='Eval Loss')\n",
    "axes[0, 1].set_title('Evaluation Loss Over Epochs')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].text(0.7, 0.8, f'Final Loss: {eval_loss[-1]:.3f}',\n",
    "                transform=axes[0, 1].transAxes,\n",
    "                bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "\n",
    "# Plot 3: Accuracy Histogram\n",
    "axes[1, 0].hist(eval_acc, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[1, 0].set_title('Evaluation Accuracy Distribution')\n",
    "axes[1, 0].set_xlabel('Accuracy')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].axvline(np.mean(eval_acc), color='red', linestyle='--',\n",
    "                   label=f'Mean: {np.mean(eval_acc):.3f}')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Smoothed Accuracy (rolling average)\n",
    "window_size = max(1, len(eval_acc) // 10)\n",
    "acc_df = pd.DataFrame({'accuracy': eval_acc})\n",
    "smoothed_acc = acc_df['accuracy'].rolling(window=window_size, center=True).mean()\n",
    "\n",
    "axes[1, 1].plot(epochs, eval_acc, 'lightblue', alpha=0.5, label='Raw Accuracy')\n",
    "axes[1, 1].plot(epochs, smoothed_acc, 'darkblue', linewidth=3, label='Smoothed Accuracy')\n",
    "axes[1, 1].set_title('Raw vs Smoothed Evaluation Accuracy')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448eb1a4",
   "metadata": {},
   "source": [
    "## 4. Compare Training vs Validation Accuracy\n",
    "Create side-by-side plots or overlaid plots to compare training and validation accuracy to identify overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459400e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# === Find and Load Hugging Face trainer_state.json ===\n",
    "possible_paths = [\n",
    "    \"./trainer_state.json\",                   \n",
    "    \"./results/trainer_state.json\",           \n",
    "    \"./fine_tuned_sentiment_model/trainer_state.json\",  \n",
    "]\n",
    "\n",
    "search_pattern = \"**/trainer_state.json\"\n",
    "found_files = glob.glob(search_pattern, recursive=True)\n",
    "filtered_files = [f for f in found_files if 'multilabel' not in f.lower()]\n",
    "possible_paths.extend(filtered_files)\n",
    "\n",
    "trainer_state_path = None\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        trainer_state_path = path\n",
    "        print(f\"Found trainer_state.json at: {path}\")\n",
    "        break\n",
    "\n",
    "if trainer_state_path:\n",
    "    try:\n",
    "        with open(trainer_state_path, \"r\") as f:\n",
    "            state = json.load(f)\n",
    "        logs = state.get(\"log_history\", [])\n",
    "        print(f\"Successfully loaded {len(logs)} log entries\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {trainer_state_path}: {e}\")\n",
    "        logs = []\n",
    "else:\n",
    "    print(\"trainer_state.json not found in any of these locations:\")\n",
    "    for path in possible_paths[:3]:\n",
    "        print(f\"  - {path}\")\n",
    "    print(\"\\nCreating sample data for demonstration...\")\n",
    "    logs = []\n",
    "\n",
    "if not logs:\n",
    "    print(\"Using sample training data...\")\n",
    "    sample_logs = []\n",
    "    for step in range(0, 1500, 100):\n",
    "        epoch = step / 500\n",
    "        sample_logs.append({\n",
    "            \"step\": step,\n",
    "            \"loss\": 1.2 * np.exp(-step / 800) + 0.1 + np.random.normal(0, 0.05),\n",
    "            \"learning_rate\": 2e-5 * (1 - step / 1500),\n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "        if step % 500 == 0 and step > 0:\n",
    "            sample_logs.append({\n",
    "                \"step\": step,\n",
    "                \"eval_loss\": 1.0 * np.exp(-step / 800) + 0.15 + np.random.normal(0, 0.03),\n",
    "                \"eval_accuracy\": 0.65 + 0.25 * (1 - np.exp(-step / 800)) + np.random.normal(0, 0.02),\n",
    "                \"eval_runtime\": 10.5,\n",
    "                \"eval_samples_per_second\": 50.0,\n",
    "                \"epoch\": epoch\n",
    "            })\n",
    "    logs = sample_logs\n",
    "\n",
    "# Extract metrics (using epochs)\n",
    "train_epochs, train_loss, learning_rates = [], [], []\n",
    "eval_epochs, eval_acc, eval_loss = [], [], []\n",
    "\n",
    "for entry in logs:\n",
    "    if \"loss\" in entry and \"eval_loss\" not in entry:\n",
    "        train_epochs.append(entry[\"epoch\"])\n",
    "        train_loss.append(entry[\"loss\"])\n",
    "        if \"learning_rate\" in entry:\n",
    "            learning_rates.append(entry[\"learning_rate\"])\n",
    "    if \"eval_accuracy\" in entry:\n",
    "        eval_epochs.append(entry[\"epoch\"])\n",
    "        eval_acc.append(entry[\"eval_accuracy\"])\n",
    "        if \"eval_loss\" in entry:\n",
    "            eval_loss.append(entry[\"eval_loss\"])\n",
    "\n",
    "train_epochs = np.array(train_epochs)\n",
    "train_loss = np.array(train_loss)\n",
    "learning_rates = np.array(learning_rates) if learning_rates else np.array([])\n",
    "eval_epochs = np.array(eval_epochs)\n",
    "eval_acc = np.array(eval_acc)\n",
    "eval_loss = np.array(eval_loss)\n",
    "\n",
    "print(f\"\\nExtracted metrics:\")\n",
    "print(f\"  Training epochs: {len(train_epochs)}\")\n",
    "print(f\"  Evaluation epochs: {len(eval_epochs)}\")\n",
    "print(f\"  Learning rate entries: {len(learning_rates)}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 5))\n",
    "fig.suptitle('Sentiment Model Training Progress Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Training Loss over epochs\n",
    "if len(train_epochs) > 0:\n",
    "    axes[0, 0].plot(train_epochs, train_loss, 'b-', linewidth=2, label='Training Loss', alpha=0.8)\n",
    "    axes[0, 0].set_title('Training Loss Over Epochs', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epochs')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    if len(train_loss) > 0:\n",
    "        final_loss = train_loss[-1]\n",
    "        axes[0, 0].text(0.02, 0.98, f\"Final Loss: {final_loss:.3f}\",\n",
    "                       transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "                       bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "# Plot 2: Validation Accuracy over epochs\n",
    "if len(eval_epochs) > 0:\n",
    "    axes[0, 1].plot(eval_epochs, eval_acc, 'r-', linewidth=2, label='Validation Accuracy', alpha=0.8)\n",
    "    axes[0, 1].set_title('Validation Accuracy Over Epochs', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epochs')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    final_acc = eval_acc[-1]\n",
    "    axes[0, 1].text(0.02, 0.98, f\"Final Accuracy: {final_acc:.3f}\",\n",
    "                   transform=axes[0, 1].transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "\n",
    "# Plot 3: Learning Rate Schedule (if available)\n",
    "if len(learning_rates) > 0:\n",
    "    axes[1, 0].plot(train_epochs[:len(learning_rates)], learning_rates, 'g-', linewidth=2, alpha=0.8)\n",
    "    axes[1, 0].set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epochs')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'No Learning Rate Data Available', \n",
    "                   transform=axes[1, 0].transAxes, ha='center', va='center',\n",
    "                   fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    axes[1, 0].set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 4: Validation Accuracy Improvement (epoch-to-epoch change)\n",
    "if len(eval_acc) > 1:\n",
    "    improvement = np.diff(eval_acc)\n",
    "    axes[1, 1].plot(eval_epochs[1:], improvement, 'purple', linewidth=2, alpha=0.7)\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[1, 1].fill_between(eval_epochs[1:], improvement, 0,\n",
    "                           where=(improvement > 0),\n",
    "                           color='green', alpha=0.3, label='Improvement')\n",
    "    axes[1, 1].fill_between(eval_epochs[1:], improvement, 0,\n",
    "                           where=(improvement <= 0),\n",
    "                           color='red', alpha=0.3, label='Degradation')\n",
    "    axes[1, 1].set_title('Validation Accuracy Change per Epoch', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epochs')\n",
    "    axes[1, 1].set_ylabel('Accuracy Change')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'Insufficient Evaluation Data', \n",
    "                   transform=axes[1, 1].transAxes, ha='center', va='center',\n",
    "                   fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    axes[1, 1].set_title('Validation Accuracy Change per Epoch', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_training_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('sentiment_training_summary.pdf', bbox_inches='tight')\n",
    "print(\"Summary plot saved as 'sentiment_training_summary.png' and 'sentiment_training_summary.pdf'\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SENTIMENT MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(train_loss) > 0:\n",
    "    print(f\"Training Loss:\")\n",
    "    print(f\"  Initial Loss: {train_loss[0]:.4f}\")\n",
    "    print(f\"  Final Loss: {train_loss[-1]:.4f}\")\n",
    "    print(f\"  Loss Reduction: {train_loss[0] - train_loss[-1]:.4f}\")\n",
    "    print(f\"  Best (Lowest) Loss: {np.min(train_loss):.4f}\")\n",
    "\n",
    "if len(eval_acc) > 0:\n",
    "    print(f\"\\nValidation Accuracy:\")\n",
    "    print(f\"  Initial Accuracy: {eval_acc[0]:.4f}\")\n",
    "    print(f\"  Final Accuracy: {eval_acc[-1]:.4f}\")\n",
    "    print(f\"  Total Improvement: {eval_acc[-1] - eval_acc[0]:.4f}\")\n",
    "    print(f\"  Average Accuracy: {np.mean(eval_acc):.4f}\")\n",
    "    print(f\"  Best Accuracy: {np.max(eval_acc):.4f}\")\n",
    "    print(f\"  Accuracy Std Dev: {np.std(eval_acc):.4f}\")\n",
    "\n",
    "if len(train_loss) > 0 and len(eval_acc) > 0:\n",
    "    print(f\"\\nOverall Training Health:\")\n",
    "    loss_trend = \"decreasing\" if train_loss[-1] < train_loss[0] else \"increasing\"\n",
    "    acc_trend = \"improving\" if eval_acc[-1] > eval_acc[0] else \"declining\"\n",
    "    print(f\"  Loss trend: {loss_trend}\")\n",
    "    print(f\"  Accuracy trend: {acc_trend}\")\n",
    "    if loss_trend == \"decreasing\" and acc_trend == \"improving\":\n",
    "        print(f\" Training appears healthy - loss decreasing, accuracy improving\")\n",
    "    else:\n",
    "        print(f\"  Check training - unusual trends detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faff579",
   "metadata": {},
   "source": [
    "## 5. Create Interactive Accuracy Plots\n",
    "Use plotly to create interactive plots that allow zooming and hovering over data points for detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47dc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "trainer_state_path = \"./multilabel_results/checkpoint-810/trainer_state.json\"\n",
    "\n",
    "# Load Trainer State JSON\n",
    "if os.path.exists(trainer_state_path):\n",
    "    try:\n",
    "        with open(trainer_state_path, \"r\") as f:\n",
    "            state = json.load(f)\n",
    "        logs = state.get(\"log_history\", [])\n",
    "        print(f\"Successfully loaded {len(logs)} log entries from {trainer_state_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {trainer_state_path}: {e}\")\n",
    "        logs = []\n",
    "else:\n",
    "    print(f\"âš ï¸ {trainer_state_path} not found. Using synthetic demo data...\")\n",
    "    logs = []\n",
    "\n",
    "# If no logs, create sample data\n",
    "if not logs:\n",
    "    sample_logs = []\n",
    "    for step in range(0, 1500, 100):\n",
    "        sample_logs.append({\n",
    "            \"step\": step,\n",
    "            \"loss\": 1.2 * np.exp(-step / 800) + 0.1 + np.random.normal(0, 0.05),\n",
    "            \"learning_rate\": 2e-5 * (1 - step / 1500),\n",
    "            \"epoch\": step / 500\n",
    "        })\n",
    "        if step % 500 == 0 and step > 0:\n",
    "            sample_logs.append({\n",
    "                \"step\": step,\n",
    "                \"eval_loss\": 1.0 * np.exp(-step / 800) + 0.15 + np.random.normal(0, 0.03),\n",
    "                \"eval_accuracy\": 0.65 + 0.25 * (1 - np.exp(-step / 800)) + np.random.normal(0, 0.02),\n",
    "                \"eval_f1_macro\": 0.55 + 0.35 * (1 - np.exp(-step / 800)) + np.random.normal(0, 0.02),\n",
    "                \"eval_runtime\": 10.5,\n",
    "                \"eval_samples_per_second\": 50.0,\n",
    "                \"epoch\": step / 500\n",
    "            })\n",
    "    logs = sample_logs\n",
    "\n",
    "# Extract metrics\n",
    "train_steps, train_loss, learning_rates = [], [], []\n",
    "eval_steps, eval_acc, eval_loss, eval_f1 = [], [], [], []\n",
    "\n",
    "for entry in logs:\n",
    "    if \"loss\" in entry and \"eval_loss\" not in entry:\n",
    "        train_steps.append(entry.get(\"step\", len(train_steps)))\n",
    "        train_loss.append(entry[\"loss\"])\n",
    "        if \"learning_rate\" in entry:\n",
    "            learning_rates.append(entry[\"learning_rate\"])\n",
    "    if \"eval_accuracy\" in entry or \"eval_f1_macro\" in entry:\n",
    "        eval_steps.append(entry.get(\"step\", len(eval_steps)))\n",
    "        eval_loss.append(entry.get(\"eval_loss\", np.nan))\n",
    "        eval_acc.append(entry.get(\"eval_accuracy\", np.nan))\n",
    "        eval_f1.append(entry.get(\"eval_f1_macro\", np.nan))\n",
    "\n",
    "train_steps = np.array(train_steps)\n",
    "train_loss = np.array(train_loss)\n",
    "learning_rates = np.array(learning_rates)\n",
    "eval_steps = np.array(eval_steps)\n",
    "eval_acc = np.array(eval_acc)\n",
    "eval_loss = np.array(eval_loss)\n",
    "eval_f1 = np.array(eval_f1)\n",
    "\n",
    "print(f\"\\nðŸ“Š Extracted metrics:\")\n",
    "print(f\"  Training steps: {len(train_steps)}\")\n",
    "print(f\"  Evaluation steps: {len(eval_steps)}\")\n",
    "print(f\"  Learning rate entries: {len(learning_rates)}\")\n",
    "print(f\"  Eval Accuracy entries: {np.count_nonzero(~np.isnan(eval_acc))}\")\n",
    "print(f\"  Eval F1 entries: {np.count_nonzero(~np.isnan(eval_f1))}\")\n",
    "\n",
    "# Plot 2Ã—2 summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "fig.suptitle('Multilabel Model Training Progress Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "if len(train_steps) > 0:\n",
    "    axes[0, 0].plot(train_steps, train_loss, 'b-', linewidth=2, label='Training Loss', alpha=0.8)\n",
    "    axes[0, 0].set_title('Training Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Steps'); axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend(); axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].text(0.02, 0.98, f\"Final: {train_loss[-1]:.3f}\",\n",
    "                   transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "if len(eval_acc) > 0:\n",
    "    axes[0, 1].plot(eval_steps, eval_acc, 'r-', linewidth=2, label='Val Accuracy', alpha=0.8)\n",
    "    axes[0, 1].set_title('Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Steps'); axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend(); axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].text(0.02, 0.98, f\"Final: {eval_acc[-1]:.3f}\",\n",
    "                   transform=axes[0, 1].transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "\n",
    "if len(learning_rates) > 0:\n",
    "    axes[1, 0].plot(train_steps[:len(learning_rates)], learning_rates, 'g-', linewidth=2, alpha=0.8)\n",
    "    axes[1, 0].set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Steps'); axes[1, 0].set_ylabel('LR')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'No LR Data',\n",
    "                   transform=axes[1, 0].transAxes, ha='center', va='center',\n",
    "                   fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    axes[1, 0].set_title('Learning Rate Schedule', fontsize=12, fontweight='bold')\n",
    "\n",
    "if len(eval_f1) > 0:\n",
    "    axes[1, 1].plot(eval_steps, eval_f1, 'm-', linewidth=2, label='Val F1 (macro)', alpha=0.8)\n",
    "    axes[1, 1].set_title('Validation F1 (macro)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Steps'); axes[1, 1].set_ylabel('F1 Score')\n",
    "    axes[1, 1].legend(); axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].text(0.02, 0.98, f\"Final: {eval_f1[-1]:.3f}\",\n",
    "                   transform=axes[1, 1].transAxes, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='violet', alpha=0.8))\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'No F1 Data',\n",
    "                   transform=axes[1, 1].transAxes, ha='center', va='center',\n",
    "                   fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    axes[1, 1].set_title('Validation F1 (macro)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multilabel_training_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print Training Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“‹ MULTILABEL MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(train_loss) > 0:\n",
    "    print(f\"Training Loss:\")\n",
    "    print(f\"  Initial: {train_loss[0]:.4f}\")\n",
    "    print(f\"  Final: {train_loss[-1]:.4f}\")\n",
    "    print(f\"  Reduction: {train_loss[0] - train_loss[-1]:.4f}\")\n",
    "    print(f\"  Best (min): {np.min(train_loss):.4f}\")\n",
    "\n",
    "if len(eval_acc) > 0:\n",
    "    print(f\"\\nValidation Accuracy:\")\n",
    "    print(f\"  Initial: {eval_acc[0]:.4f}\")\n",
    "    print(f\"  Final: {eval_acc[-1]:.4f}\")\n",
    "    print(f\"  Best: {np.nanmax(eval_acc):.4f}\")\n",
    "\n",
    "if len(eval_f1) > 0:\n",
    "    print(f\"\\nValidation F1 (macro):\")\n",
    "    print(f\"  Initial: {eval_f1[0]:.4f}\")\n",
    "    print(f\"  Final: {eval_f1[-1]:.4f}\")\n",
    "    print(f\"  Best: {np.nanmax(eval_f1):.4f}\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
