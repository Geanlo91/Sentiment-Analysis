{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001c45ae-34c5-4681-ac24-8b242fcfb5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Initial dataset size: 7472 rows\n",
      "Missing review texts: 0\n",
      "Cleaning text data...\n",
      "After removing empty texts: 7472 rows\n",
      "After removing very short texts: 7472 rows\n",
      "After removing very long texts: 7435 rows\n",
      "Missing labels: 0\n",
      "After removing invalid labels: 7435 rows\n",
      "Removed 184 duplicate reviews\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0    1095\n",
      "1    1892\n",
      "2    4264\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final cleaned dataset size: 7251 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab84118c8db4a089c8d0a3ed5115b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/29 12:45:42 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6990a8f0e7394a30a6f1fcc0a9300ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/546 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3399, 'grad_norm': 6.6044697761535645, 'learning_rate': 1.8548387096774196e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71054b662c194a5c98ba40f16e8746d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4641847610473633, 'eval_accuracy': 0.8456237077877325, 'eval_f1': 0.8448316496857904, 'eval_runtime': 572.091, 'eval_samples_per_second': 2.536, 'eval_steps_per_second': 0.08, 'epoch': 2.75}\n",
      "{'train_runtime': 60707.2386, 'train_samples_per_second': 0.287, 'train_steps_per_second': 0.009, 'train_loss': 0.3262126122638856, 'epoch': 3.0}\n",
      "Fine-tuned model saved to fine_tuned_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, EarlyStoppingCallback, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "MAX_LENGTH = 152\n",
    "NUM_LABELS = 3\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "BASE_MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "FINE_TUNED_MODEL_DIR = \"fine_tuned_sentiment_model\"\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess text data\"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove URLs, email addresses, whitespace\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def validate_and_clean_data(df):\n",
    "    \"\"\"Comprehensive data validation and cleaning\"\"\"\n",
    "    print(f\"Initial dataset size: {len(df)} rows\")\n",
    "    \n",
    "    # Check required columns\n",
    "    required_cols = [\"review\", \"label\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Required column '{col}' not found in CSV!\")\n",
    "    \n",
    "    # Handle missing review text\n",
    "    print(f\"Missing review texts: {df['review'].isna().sum()}\")\n",
    "    df = df.dropna(subset=['review'])\n",
    "    \n",
    "    # Clean text data\n",
    "    print(\"Cleaning text data...\")\n",
    "    df['review'] = df['review'].apply(clean_text)\n",
    "    \n",
    "    # Remove empty texts after cleaning\n",
    "    df = df[df['review'].str.len() > 0]\n",
    "    print(f\"After removing empty texts: {len(df)} rows\")\n",
    "    \n",
    "    # Remove very short texts (less than 3 characters)\n",
    "    df = df[df['review'].str.len() >= 3]\n",
    "    print(f\"After removing very short texts: {len(df)} rows\")\n",
    "    \n",
    "    # Remove very long texts (keep within reasonable limits)\n",
    "    df = df[df['review'].str.len() <= 1000]\n",
    "    print(f\"After removing very long texts: {len(df)} rows\")\n",
    "    \n",
    "    # Label validation and cleaning\n",
    "    print(f\"Missing labels: {df['label'].isna().sum()}\")\n",
    "    \n",
    "    # Convert labels to numeric, invalid ones become NaN\n",
    "    df['label'] = pd.to_numeric(df['label'], errors='coerce')\n",
    "    \n",
    "    # Remove rows with invalid labels\n",
    "    df = df.dropna(subset=['label'])\n",
    "    print(f\"After removing invalid labels: {len(df)} rows\")\n",
    "    \n",
    "    # Ensure labels are within valid range (0, 1, 2 for sentiment)\n",
    "    valid_labels = df['label'].isin([0, 1, 2])\n",
    "    invalid_count = (~valid_labels).sum()\n",
    "    if invalid_count > 0:\n",
    "        print(f\"Removing {invalid_count} rows with invalid label values\")\n",
    "        df = df[valid_labels]\n",
    "    \n",
    "    # Convert to int after validation\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    \n",
    "    # Remove duplicates based on review text\n",
    "    initial_size = len(df)\n",
    "    df = df.drop_duplicates(subset=['review'], keep='first')\n",
    "    duplicates_removed = initial_size - len(df)\n",
    "    print(f\"Removed {duplicates_removed} duplicate reviews\")\n",
    "    \n",
    "    # Show label distribution\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(df['label'].value_counts().sort_index())\n",
    "    \n",
    "    print(f\"\\nFinal cleaned dataset size: {len(df)} rows\")\n",
    "    \n",
    "    # Reset index after all the filtering\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def tokenize(batch):\n",
    "    texts = [str(x) if x is not None else \"\" for x in batch[\"review\"]]\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and clean data with robust error handling\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            \"training_data.csv\",\n",
    "            quotechar='\"',\n",
    "            escapechar='\\\\',\n",
    "            engine=\"python\",\n",
    "            on_bad_lines=\"skip\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV: {e}\")\n",
    "        print(\"Trying with basic pandas read_csv...\")\n",
    "        df = pd.read_csv(\"training_data.csv\")\n",
    "    \n",
    "    # Apply comprehensive data cleaning\n",
    "    df = validate_and_clean_data(df)\n",
    "    \n",
    "    # Check if we have enough data after cleaning\n",
    "    if len(df) < 10:\n",
    "        raise ValueError(f\"Insufficient data after cleaning: only {len(df)} rows remaining\")\n",
    "    \n",
    "    dataset = Dataset.from_pandas(df)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "    # Use fewer processes on Windows to avoid hang\n",
    "    dataset = dataset.map(tokenize, batched=True, num_proc=1)\n",
    "    dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "    dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    dataset = dataset.train_test_split(test_size=0.2)\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    eval_dataset = dataset[\"test\"]\n",
    "\n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "\n",
    "    def compute_metrics(pred):\n",
    "        logits = pred.predictions\n",
    "        labels = pred.label_ids\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        acc = accuracy.compute(predictions=preds, references=labels)\n",
    "        f1_score = f1.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "        return {\"accuracy\": acc[\"accuracy\"], \"f1\": f1_score[\"f1\"]}\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"steps\",  # evaluate less often\n",
    "        eval_steps=500,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,  # larger batch if possible\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        weight_decay=0.01,\n",
    "        warmup_steps=50,\n",
    "        fp16=True,  # mixed precision\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=500,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True\n",
    "    )\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    print(\"\\nStarting fine-tuning...\")\n",
    "    trainer.train()\n",
    "\n",
    "    trainer.save_model(FINE_TUNED_MODEL_DIR)\n",
    "    tokenizer.save_pretrained(FINE_TUNED_MODEL_DIR)\n",
    "    print(f\"Fine-tuned model saved to {FINE_TUNED_MODEL_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
